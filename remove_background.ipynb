{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 概要\n",
    "\n",
    "1枚の人物画像から背景を切り抜いて人物だけを切り出す\n",
    "\n",
    "1. trimapを作成\n",
    "2. `FBA_Matting`で背景と前景を分離\n",
    "3. 結果を保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. trimapを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'examples/images/takeshi_512_no_alpha.png'\n",
    "image_name = os.path.basename(image_path)\n",
    "mask_image_name = os.path.join('./examples/mask/', image_name)\n",
    "trimap_image_name = os.path.join('./examples/trimaps/',image_name)\n",
    "os.makedirs('./examples/mask/',exist_ok=True)\n",
    "os.makedirs('./examples/trimaps/',exist_ok=True)\n",
    "img = cv2.imread(image_path)\n",
    "img = img[...,::-1] #BGR->RGB\n",
    "h,w,_ = img.shape\n",
    "img = cv2.resize(img,(320,320))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## segmentationで人間を抜き出す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = torchvision.models.segmentation.deeplabv3_resnet101(pretrained=True)\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "input_tensor = preprocess(img)\n",
    "input_batch = input_tensor.unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(input_batch)['out'][0]\n",
    "output = output.argmax(0)\n",
    "mask = output.byte().cpu().numpy()\n",
    "mask = cv2.resize(mask,(w,h))\n",
    "img = cv2.resize(img,(w,h))\n",
    "cv2.imwrite(mask_image_name,mask)\n",
    "plt.gray()\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mask画像を拡散収縮させてtrimapを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_image(image):\n",
    "    image_bi = image.copy()\n",
    "    image_bi[np.where(image_bi > 0)] = 255\n",
    "    return image_bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_trimap(mask,k_size=(5,5),ite=1):\n",
    "    kernel = np.ones(k_size,np.uint8)\n",
    "    eroded = cv2.erode(mask,kernel,iterations = ite)\n",
    "    dilated = cv2.dilate(mask,kernel,iterations = ite)\n",
    "    eroded_bi = binarize_image(eroded)\n",
    "    dilated_bi = binarize_image(dilated)\n",
    "    trimap = np.full(mask.shape,128)\n",
    "    trimap[eroded_bi == 255] = 255\n",
    "    trimap[dilated_bi == 0] = 0\n",
    "    return trimap\n",
    "trimap = gen_trimap(mask,k_size=(5,5),ite=3)\n",
    "cv2.imwrite(trimap_image_name,trimap)\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(trimap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `FBA_Matting`で背景と前景を分離する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "if not 'FBA_Matting' in sys.path:\n",
    "    print('add path')\n",
    "    sys.path.append(os.path.join(os.path.dirname('__file__'), 'FBA_Matting'))\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from demo import np_to_torch, pred, scale_input\n",
    "from dataloader import read_image, read_trimap\n",
    "from networks.models import build_model\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "  encoder = 'resnet50_GN_WS'\n",
    "  decoder = 'fba_decoder'\n",
    "  weights = './FBA_Matting/FBA.pth'\n",
    "args=Args()\n",
    "try:\n",
    "    model = build_model(args)\n",
    "except:\n",
    "    !gdown  https://drive.google.com/uc?id=1T_oiKDE_biWf2kqexMEN7ObWqtXAzbB1\n",
    "    model = build_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = read_image(image_path)\n",
    "trimap = read_trimap(trimap_image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg, bg, alpha = pred(image, trimap, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Alpha Matte')\n",
    "plt.imshow(alpha, cmap='gray', vmin=0, vmax=1)\n",
    "plt.show()\n",
    "plt.title('Foreground')\n",
    "plt.imshow(fg)\n",
    "plt.show()\n",
    "plt.title('Background')\n",
    "plt.imshow(bg)\n",
    "plt.show()\n",
    "plt.title('Composite')\n",
    "plt.imshow(fg*alpha[:,:,None])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "!python ./FBA_Matting/demo.py --image_dir ./examples/images/ --trimap_dir ./examples/trimaps/ --output_dir ./examples/predictions/ --weights ./FBA_Matting/FBA.pth\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 結果を保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('output',exist_ok=True)\n",
    "output_file = image_name.split('.')[0] + '_fg.png'\n",
    "output_mask_file = image_name.split('.')[0] + '_fg_mask.png'\n",
    "out_fg_img = cv2.cvtColor(fg*alpha[:,:,None] * 255.0, cv2.COLOR_RGB2BGR)\n",
    "cv2.imwrite('./output/' + output_file, out_fg_img)\n",
    "cv2.imwrite('./output/' + output_mask_file, alpha * 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitremovebgconda8015702d7ce84e8cb4da0d887e67919a",
   "display_name": "Python 3.7.7 64-bit ('remove_bg': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}